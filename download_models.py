#!/usr/bin/env python3
"""
æ¨¡å‹ä¸‹è¼‰è…³æœ¬
è‡ªå‹•ä¸‹è¼‰æ‰€éœ€çš„AIæ¨¡å‹æ–‡ä»¶
"""

import os
import sys
import logging
from pathlib import Path
from huggingface_hub import snapshot_download, login
import torch

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def download_models():
    """ä¸‹è¼‰æ‰€éœ€çš„AIæ¨¡å‹"""
    
    models_to_download = [
        {
            "name": "FLAN-T5-Large (æ–‡æ¡ˆç”Ÿæˆ)",
            "repo_id": "google/flan-t5-large",
            "local_dir": "checkpoints/flan-t5-large"
        },
        {
            "name": "SDXL Base (åœ–åƒç”Ÿæˆ)",
            "repo_id": "stabilityai/stable-diffusion-xl-base-1.0", 
            "local_dir": "checkpoints/sdxl-base-1.0"
        },
        {
            "name": "SDXL Refiner (åœ–åƒå¢å¼·)",
            "repo_id": "stabilityai/stable-diffusion-xl-refiner-1.0",
            "local_dir": "checkpoints/sdxl-refiner-1.0"
        },
        {
            "name": "SVD (å½±ç‰‡ç”Ÿæˆ)",
            "repo_id": "stabilityai/stable-video-diffusion-img2vid-xt",
            "local_dir": "checkpoints/svd-img2vid-xt"
        }
    ]
    
    # æª¢æŸ¥CUDA
    if torch.cuda.is_available():
        logger.info(f"âœ… æª¢æ¸¬åˆ°GPU: {torch.cuda.get_device_name(0)}")
        logger.info(f"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
    else:
        logger.warning("âš ï¸ æœªæª¢æ¸¬åˆ°CUDA GPUï¼Œå°‡ä½¿ç”¨CPUæ¨¡å¼")
    
    # å‰µå»ºcheckpointsç›®éŒ„
    checkpoints_dir = Path("checkpoints")
    checkpoints_dir.mkdir(exist_ok=True)
    
    # å˜—è©¦ç™»éŒ„Hugging Face (å¦‚æœæœ‰token)
    hf_token = os.getenv("HUGGINGFACE_TOKEN")
    if hf_token:
        try:
            login(token=hf_token)
            logger.info("âœ… Hugging Face ç™»éŒ„æˆåŠŸ")
        except Exception as e:
            logger.warning(f"Hugging Face ç™»éŒ„å¤±æ•—: {e}")
    
    # ä¸‹è¼‰æ¨¡å‹
    for model_info in models_to_download:
        try:
            logger.info(f"ğŸ“¥ é–‹å§‹ä¸‹è¼‰: {model_info['name']}")
            
            local_path = Path(model_info["local_dir"])
            
            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if local_path.exists() and any(local_path.iterdir()):
                logger.info(f"âœ… æ¨¡å‹å·²å­˜åœ¨ï¼Œè·³é: {model_info['name']}")
                continue
            
            # ä¸‹è¼‰æ¨¡å‹
            snapshot_download(
                repo_id=model_info["repo_id"],
                local_dir=model_info["local_dir"],
                local_dir_use_symlinks=False,
                resume_download=True
            )
            
            logger.info(f"âœ… ä¸‹è¼‰å®Œæˆ: {model_info['name']}")
            
        except Exception as e:
            logger.error(f"âŒ ä¸‹è¼‰å¤±æ•— {model_info['name']}: {e}")
            
            # å°æ–¼æŸäº›æ¨¡å‹ï¼Œæä¾›æ›¿ä»£æ–¹æ¡ˆ
            if "sdxl" in model_info["repo_id"]:
                logger.info("ğŸ’¡ æç¤º: SDXLæ¨¡å‹éœ€è¦ç´„13GBç©ºé–“ï¼Œç¢ºä¿æœ‰è¶³å¤ çš„ç£ç¢Ÿç©ºé–“")
            elif "svd" in model_info["repo_id"]:
                logger.info("ğŸ’¡ æç¤º: SVDæ¨¡å‹éœ€è¦ç´„9GBç©ºé–“å’Œ16GB+ VRAM")
    
    logger.info("ğŸ‰ æ¨¡å‹ä¸‹è¼‰æµç¨‹å®Œæˆï¼")
    
    # æª¢æŸ¥ä¸‹è¼‰çµæœ
    logger.info("\nğŸ“Š æ¨¡å‹ç‹€æ…‹æª¢æŸ¥:")
    for model_info in models_to_download:
        local_path = Path(model_info["local_dir"])
        if local_path.exists() and any(local_path.iterdir()):
            size_mb = sum(f.stat().st_size for f in local_path.rglob('*') if f.is_file()) / 1024**2
            logger.info(f"âœ… {model_info['name']}: {size_mb:.1f}MB")
        else:
            logger.warning(f"âŒ {model_info['name']}: æœªæ‰¾åˆ°")

if __name__ == "__main__":
    download_models()